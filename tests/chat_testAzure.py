import os
from openai import AzureOpenAI
from dotenv import load_dotenv

load_dotenv()

client = AzureOpenAI(
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_KEY"),
    api_version="2024-02-15-preview"
)

print("üîÑ Probando conexi√≥n con GPT-4o...")
print(f"Deployment name: {os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT')}")

try:
    # Probar el modelo de chat
    response = client.chat.completions.create(
        model=os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT"),
        messages=[
            {"role": "system", "content": "Eres un asistente √∫til."},
            {"role": "user", "content": "¬øQu√© modelo eres y cu√°les son tus capacidades principales?"}
        ],
        max_tokens=150,
        temperature=0.7
    )
    
    print("‚úÖ GPT-4o funcionando correctamente!")
    print(f"\nRespuesta del modelo:\n{response.choices[0].message.content}")
    
    # Mostrar informaci√≥n adicional
    print(f"\nüìä Tokens usados: {response.usage.total_tokens}")
    print(f"üìä Modelo: {response.model}")
    
except Exception as e:
    print(f"‚ùå Error: {e}")
    print("\nVerifica:")
    print("1. El nombre del deployment en Azure AI Foundry")
    print("2. Que el deployment est√© activo")
    print("3. Que el nombre en .env coincida exactamente")