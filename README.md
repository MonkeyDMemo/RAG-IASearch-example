# Sistema RAG (Retrieval-Augmented Generation) con Azure AI Search

## üìã Tabla de Contenidos

- [Introducci√≥n](#introducci√≥n)
- [¬øQu√© es RAG?](#qu√©-es-rag)
- [Arquitectura del Sistema](#arquitectura-del-sistema)
- [Componentes de Azure](#componentes-de-azure)
- [Instalaci√≥n y Configuraci√≥n](#instalaci√≥n-y-configuraci√≥n)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Flujo de Trabajo](#flujo-de-trabajo)
- [Gu√≠a de Uso](#gu√≠a-de-uso)
- [Estructura de Datos](#estructura-de-datos)
- [Optimizaci√≥n y Mejores Pr√°cticas](#optimizaci√≥n-y-mejores-pr√°cticas)
- [Costos y Escalabilidad](#costos-y-escalabilidad)
- [Troubleshooting](#troubleshooting)
- [Glosario](#glosario)

---

## üìñ Introducci√≥n

Este documento describe la implementaci√≥n de un sistema RAG (Retrieval-Augmented Generation) utilizando Azure AI Search y Azure OpenAI. El sistema permite procesar documentos PDF, indexar su contenido y realizar consultas inteligentes utilizando modelos de lenguaje avanzados.

### Objetivo del Sistema

Crear una base de conocimiento consultable que:
- Procese documentos PDF autom√°ticamente
- Permita b√∫squedas sem√°nticas avanzadas
- Genere respuestas precisas basadas en el contenido indexado
- Mantenga trazabilidad de las fuentes de informaci√≥n

### Casos de Uso

- **Documentaci√≥n t√©cnica**: Consultar manuales y gu√≠as t√©cnicas
- **Base de conocimiento empresarial**: Centralizar informaci√≥n corporativa
- **Investigaci√≥n**: Analizar m√∫ltiples documentos acad√©micos
- **Soporte al cliente**: Responder preguntas basadas en documentaci√≥n

---

## ü§ñ ¬øQu√© es RAG?

### Definici√≥n

RAG (Retrieval-Augmented Generation) es una arquitectura que combina:
- **Retrieval (Recuperaci√≥n)**: B√∫squeda de informaci√≥n relevante
- **Augmented (Aumentado)**: Enriquecimiento del contexto
- **Generation (Generaci√≥n)**: Creaci√≥n de respuestas usando LLMs

### ¬øPor qu√© RAG?

#### Problemas de los LLMs tradicionales:
1. **Conocimiento est√°tico**: Limitado a datos de entrenamiento
2. **Alucinaciones**: Pueden inventar informaci√≥n
3. **Sin fuentes**: No pueden citar de d√≥nde viene la informaci√≥n
4. **Desactualizaci√≥n**: No tienen informaci√≥n reciente

#### Soluci√≥n con RAG:
1. **Conocimiento din√°mico**: Actualizable en tiempo real
2. **Informaci√≥n verificable**: Basada en documentos reales
3. **Citas precisas**: Referencias a fuentes espec√≠ficas
4. **Actualizaci√≥n continua**: Agregar nuevos documentos cuando sea necesario

### Flujo RAG Conceptual

```
1. PREGUNTA DEL USUARIO
        ‚Üì
2. CONVERSI√ìN A EMBEDDING
        ‚Üì
3. B√öSQUEDA SEM√ÅNTICA
        ‚Üì
4. RECUPERACI√ìN DE CONTEXTO
        ‚Üì
5. GENERACI√ìN DE RESPUESTA
        ‚Üì
6. RESPUESTA CON FUENTES
```

---

## üèóÔ∏è Arquitectura del Sistema

### Arquitectura General

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 ‚îÇ     ‚îÇ                  ‚îÇ     ‚îÇ                 ‚îÇ
‚îÇ   Documentos    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Procesamiento  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Azure Search   ‚îÇ
‚îÇ     (PDFs)      ‚îÇ     ‚îÇ   & Embeddings   ‚îÇ     ‚îÇ     Index       ‚îÇ
‚îÇ                 ‚îÇ     ‚îÇ                  ‚îÇ     ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ                           ‚îÇ
                               ‚îÇ                           ‚îÇ
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
                        ‚îÇ                 ‚îÇ               ‚îÇ
                        ‚îÇ  Azure OpenAI   ‚îÇ               ‚îÇ
                        ‚îÇ   Embeddings    ‚îÇ               ‚îÇ
                        ‚îÇ                 ‚îÇ               ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
                                                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ                 ‚îÇ     ‚îÇ                  ‚îÇ            ‚îÇ
‚îÇ     Usuario     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Consulta      ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ                 ‚îÇ     ‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚ñ≤                        ‚îÇ
        ‚îÇ                        ‚îÇ
        ‚îÇ               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ               ‚îÇ                  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   Azure OpenAI   ‚îÇ
                       ‚îÇ      GPT-4o       ‚îÇ
                       ‚îÇ                  ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes Principales

#### 1. **Capa de Ingesta**
- Lectura de PDFs
- Extracci√≥n de texto
- Divisi√≥n en chunks
- Generaci√≥n de metadatos

#### 2. **Capa de Procesamiento**
- Generaci√≥n de embeddings
- Validaci√≥n de datos
- Gesti√≥n de errores
- Logging

#### 3. **Capa de Almacenamiento**
- Azure AI Search Index
- Vectores de embeddings
- Metadatos estructurados
- √çndices de b√∫squeda

#### 4. **Capa de B√∫squeda**
- B√∫squeda h√≠brida (texto + vectorial)
- Ranking de relevancia
- Filtros y facetas
- Recuperaci√≥n de contexto

#### 5. **Capa de Generaci√≥n**
- Construcci√≥n de prompts
- Llamadas a GPT-4o
- Post-procesamiento
- Formateo de respuestas

---

## ‚òÅÔ∏è Componentes de Azure

### Azure AI Search

#### ¬øQu√© es?
Servicio de b√∫squeda como servicio (SaaS) que proporciona:
- Indexaci√≥n de documentos
- B√∫squeda de texto completo
- B√∫squeda vectorial/sem√°ntica
- B√∫squeda h√≠brida

#### Configuraci√≥n utilizada:
- **Tier**: Basic o Standard
- **Replicas**: 1 (m√≠nimo)
- **Particiones**: 1 (m√≠nimo)
- **√çndice**: `pdf-index-v2`

#### Campos del √≠ndice:
```json
{
  "fields": [
    {"name": "id", "type": "Edm.String", "key": true},
    {"name": "content", "type": "Edm.String", "searchable": true},
    {"name": "content_vector", "type": "Collection(Edm.Single)", "dimensions": 1536},
    {"name": "source", "type": "Edm.String", "filterable": true},
    {"name": "page", "type": "Edm.Int32", "filterable": true},
    {"name": "fecha_carga", "type": "Edm.DateTimeOffset", "filterable": true}
  ]
}
```

### Azure OpenAI

#### Modelos desplegados:

1. **text-embedding-ada-002**
   - Uso: Generaci√≥n de embeddings
   - Dimensiones: 1536
   - Costo: ~$0.0001 por 1K tokens

2. **GPT-4o**
   - Uso: Generaci√≥n de respuestas
   - Contexto: 128K tokens
   - Costo: ~$0.005 por 1K tokens input, ~$0.015 por 1K tokens output

#### Configuraci√≥n de deployments:
- **Rate limit**: 50,000 TPM (Tokens por minuto)
- **Regi√≥n**: Seleccionar la m√°s cercana
- **Versi√≥n API**: 2024-02-15-preview

---

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

#### Software necesario:
- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- Git (opcional)

#### Cuentas necesarias:
- Suscripci√≥n de Azure activa
- Acceso a Azure OpenAI (requiere aprobaci√≥n)

### Paso 1: Crear recursos en Azure

#### 1.1 Azure AI Search
```bash
# Azure CLI
az search service create \
  --name mi-search-rag \
  --resource-group mi-grupo \
  --sku basic \
  --location eastus
```

#### 1.2 Azure OpenAI
```bash
# Azure CLI
az cognitiveservices account create \
  --name mi-openai-rag \
  --resource-group mi-grupo \
  --kind OpenAI \
  --sku S0 \
  --location eastus
```

### Paso 2: Configurar el entorno local

#### 2.1 Clonar o crear el proyecto
```bash
mkdir rag-azure-system
cd rag-azure-system
```

#### 2.2 Instalar dependencias
```bash
pip install -r requirements.txt
```

**requirements.txt:**
```
azure-search-documents==11.4.0
openai==1.3.0
PyPDF2==3.0.1
python-dotenv==1.0.0
azure-core==1.29.0
```

#### 2.3 Configurar variables de entorno

Crear archivo `.env`:
```env
# Azure Search
AZURE_SEARCH_ENDPOINT=https://mi-search-rag.search.windows.net
AZURE_SEARCH_KEY=tu-admin-key
AZURE_SEARCH_INDEX_NAME=pdf-index-v2

# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://mi-openai-rag.openai.azure.com/
AZURE_OPENAI_KEY=tu-openai-key
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=embeddings
AZURE_OPENAI_CHAT_DEPLOYMENT=chat
```

### Paso 3: Desplegar modelos en Azure AI Foundry

1. Acceder a [ai.azure.com](https://ai.azure.com)
2. Crear/seleccionar proyecto
3. Ir a "Deployments"
4. Desplegar:
   - `text-embedding-ada-002` como "embeddings"
   - `gpt-4o` como "chat"

---

## üìÅ Estructura del Proyecto

### Organizaci√≥n de archivos

```
rag-azure-system/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Scripts principales
‚îÇ   ‚îú‚îÄ‚îÄ cargar_pdf.py          # Carga documentos al √≠ndice
‚îÇ   ‚îú‚îÄ‚îÄ consultar.py           # Realiza consultas
‚îÇ   ‚îî‚îÄ‚îÄ gestionar_indice.py    # Administraci√≥n del √≠ndice
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Scripts auxiliares
‚îÇ   ‚îú‚îÄ‚îÄ verificar_config.py    # Verifica configuraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ migrar_indice.py       # Migraci√≥n de √≠ndices
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Documentos
‚îÇ   ‚îî‚îÄ‚îÄ pdfs/                  # Carpeta para PDFs
‚îÇ       ‚îú‚îÄ‚îÄ documento1.pdf
‚îÇ       ‚îî‚îÄ‚îÄ documento2.pdf
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ .env                   # Variables de entorno
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       # Dependencias Python
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Logs y salidas
‚îÇ   ‚îú‚îÄ‚îÄ carga_documentos_log.txt
‚îÇ   ‚îú‚îÄ‚îÄ historial_consultas_*.txt
‚îÇ   ‚îî‚îÄ‚îÄ estadisticas_indice_*.json
‚îÇ
‚îî‚îÄ‚îÄ üìÑ Documentaci√≥n
    ‚îî‚îÄ‚îÄ README.md
```

### Descripci√≥n de scripts

#### **cargar_pdf.py**
- **Funci√≥n**: Procesar y cargar PDFs al √≠ndice
- **Caracter√≠sticas**:
  - Verificaci√≥n de duplicados
  - Procesamiento por lotes
  - Generaci√≥n de embeddings
  - Logging detallado

#### **consultar.py**
- **Funci√≥n**: Realizar consultas al sistema
- **Caracter√≠sticas**:
  - B√∫squeda h√≠brida
  - Filtros por documento
  - Historial de consultas
  - Modo interactivo y batch

#### **gestionar_indice.py**
- **Funci√≥n**: Administrar el √≠ndice
- **Caracter√≠sticas**:
  - Ver estad√≠sticas
  - Eliminar documentos
  - Exportar informaci√≥n
  - Detectar duplicados

---

## üîÑ Flujo de Trabajo

### 1. Carga de Documentos

#### Proceso detallado:

1. **Lectura del PDF**
   ```python
   pdf_reader = PyPDF2.PdfReader(file)
   ```

2. **Extracci√≥n por p√°ginas**
   ```python
   for page_num in range(total_pages):
       text = page.extract_text()
   ```

3. **Divisi√≥n en chunks**
   - Tama√±o: 500 caracteres
   - Overlap: 100 caracteres
   - Validaci√≥n: m√≠nimo 50 caracteres

4. **Generaci√≥n de embeddings**
   ```python
   embedding = openai_client.embeddings.create(
       input=chunk_text,
       model="embeddings"
   )
   ```

5. **Carga al √≠ndice**
   ```python
   search_client.upload_documents(documents=chunks)
   ```

### 2. Proceso de Consulta

#### Proceso detallado:

1. **Recepci√≥n de pregunta**
   ```python
   pregunta = input("Tu pregunta: ")
   ```

2. **Generaci√≥n de embedding**
   ```python
   pregunta_vector = generar_embedding(pregunta)
   ```

3. **B√∫squeda h√≠brida**
   ```python
   results = search_client.search(
       search_text=pregunta,
       vector_queries=[vector_query],
       top=5
   )
   ```

4. **Construcci√≥n de prompt**
   ```python
   contexto = "\n".join([chunk["content"] for chunk in results])
   prompt = f"Contexto: {contexto}\nPregunta: {pregunta}"
   ```

5. **Generaci√≥n de respuesta**
   ```python
   response = openai_client.chat.completions.create(
       model="chat",
       messages=[{"role": "user", "content": prompt}]
   )
   ```

---

## üìñ Gu√≠a de Uso

### Caso de Uso 1: Primera carga de documentos

```bash
# 1. Verificar configuraci√≥n
python verificar_config.py

# 2. Cargar un PDF individual
python cargar_pdf.py
> Opci√≥n: 1
> Ruta: documento.pdf

# 3. Verificar carga
python gestionar_indice.py
> Opci√≥n: 1 (Ver informaci√≥n)
```

### Caso de Uso 2: Consultas sobre documentos

```bash
# Modo interactivo
python consultar.py

# Ejemplos de consultas:
> ¬øQu√© es la IA generativa?
> ¬øCu√°les son los componentes principales de MCP?
> filtrar:MCP_explained.pdf
> ¬øQu√© dice sobre arquitectura?
```

### Caso de Uso 3: Procesamiento batch

```bash
# Crear archivo preguntas.txt
echo "¬øQu√© es RAG?" > preguntas.txt
echo "¬øC√≥mo funciona Azure Search?" >> preguntas.txt

# Procesar
python consultar.py preguntas.txt

# Resultados en: respuestas_[timestamp].txt
```

### Caso de Uso 4: Gesti√≥n del √≠ndice

```bash
python gestionar_indice.py

# Opciones disponibles:
# 1. Ver informaci√≥n del √≠ndice
# 2. Listar documentos
# 3. Eliminar documento espec√≠fico
# 4. Limpiar todo el √≠ndice
# 5. Exportar estad√≠sticas
# 6. Buscar duplicados
```

---

## üóÇÔ∏è Estructura de Datos

### Esquema del Chunk

```json
{
  "id": "d3f4a8b2c9e1f6a8b3d2e1f9",
  "content": "La inteligencia artificial generativa es una rama...",
  "content_vector": [0.023, -0.045, 0.127, ...],
  "source": "introduccion_ia.pdf",
  "page": 5,
  "fecha_carga": "2024-08-22T10:30:00Z"
}
```

### Campos explicados:

| Campo | Tipo | Descripci√≥n | Uso |
|-------|------|-------------|-----|
| **id** | String | Identificador √∫nico hash MD5 | Clave primaria |
| **content** | String | Texto del chunk | B√∫squeda textual |
| **content_vector** | Float[] | Embedding de 1536 dimensiones | B√∫squeda sem√°ntica |
| **source** | String | Nombre del documento origen | Filtrado y citaci√≥n |
| **page** | Int32 | N√∫mero de p√°gina | Referencias precisas |
| **fecha_carga** | DateTime | Timestamp de carga | Auditor√≠a |

### Configuraci√≥n de b√∫squeda

#### B√∫squeda h√≠brida:
```python
VectorizedQuery(
    vector=embedding,
    k_nearest_neighbors=5,
    fields="content_vector"
)
```

#### Algoritmo HNSW:
```python
HnswAlgorithmConfiguration(
    m=4,                    # Conexiones por nodo
    efConstruction=400,     # Calidad de construcci√≥n
    efSearch=500,          # Calidad de b√∫squeda
    metric="cosine"        # M√©trica de distancia
)
```

---

## ‚ö° Optimizaci√≥n y Mejores Pr√°cticas

### 1. Tama√±o de Chunks

#### Recomendaciones:
- **Peque√±os (300-500 chars)**: Mayor precisi√≥n, m√°s tokens
- **Medianos (500-1000 chars)**: Balance √≥ptimo
- **Grandes (1000-2000 chars)**: M√°s contexto, menos precisi√≥n

```python
# Configuraci√≥n recomendada
CHUNK_SIZE = 500
OVERLAP = 100
MIN_CHUNK_LENGTH = 50
```

### 2. N√∫mero de resultados (top_k)

```python
# Configuraci√≥n seg√∫n caso de uso
TOP_K_SIMPLE = 3      # Preguntas simples
TOP_K_COMPLEX = 5     # Preguntas complejas
TOP_K_RESEARCH = 10   # Investigaci√≥n profunda
```

### 3. Temperatura del modelo

```python
# Configuraci√≥n seg√∫n tipo de respuesta
TEMPERATURE_FACTUAL = 0.3    # Respuestas precisas
TEMPERATURE_BALANCED = 0.5   # Balance
TEMPERATURE_CREATIVE = 0.7   # Respuestas creativas
```

### 4. Procesamiento por lotes

```python
# Para grandes vol√∫menes
BATCH_SIZE = 100  # Documentos por lote
RETRY_ATTEMPTS = 3
RETRY_DELAY = 5  # segundos
```

### 5. Cach√© de embeddings

```python
# Evitar regenerar embeddings
embedding_cache = {}

def get_embedding_cached(text):
    if text not in embedding_cache:
        embedding_cache[text] = generate_embedding(text)
    return embedding_cache[text]
```

### 6. Validaci√≥n de calidad

```python
# Verificar calidad de chunks
def validate_chunk(chunk):
    # Longitud m√≠nima
    if len(chunk) < MIN_CHUNK_LENGTH:
        return False
    
    # Contenido significativo
    if chunk.count(' ') < 5:  # Muy pocas palabras
        return False
    
    # No solo n√∫meros o s√≠mbolos
    if not any(c.isalpha() for c in chunk):
        return False
    
    return True
```

---

## üí∞ Costos y Escalabilidad

### Estructura de costos

#### Azure AI Search
| Tier | Costo/mes | Documentos | √çndices | Uso recomendado |
|------|-----------|------------|---------|-----------------|
| Free | $0 | 10,000 | 3 | Desarrollo |
| Basic | ~$75 | 15M | 15 | Producci√≥n peque√±a |
| Standard S1 | ~$250 | 1M/partici√≥n | 50 | Producci√≥n media |
| Standard S2 | ~$1,000 | 1M/partici√≥n | 200 | Producci√≥n grande |

#### Azure OpenAI
| Operaci√≥n | Modelo | Costo aproximado |
|-----------|--------|------------------|
| Embeddings | ada-002 | $0.0001/1K tokens |
| Consulta | GPT-4o | $0.005/1K input + $0.015/1K output |

### Ejemplo de costos mensuales

Para un sistema con:
- 100 PDFs (‚âà5,000 chunks)
- 1,000 consultas/mes
- Azure Search Basic

```
Azure Search Basic:        $75.00
Embeddings iniciales:      $5.00
Consultas (1,000):         $20.00
--------------------------------
Total mensual:             ~$100.00
```

### Estrategias de optimizaci√≥n de costos

1. **Usar Free Tier para desarrollo**
2. **Implementar cach√© de respuestas frecuentes**
3. **Optimizar tama√±o de chunks**
4. **Usar GPT-3.5-turbo para consultas simples**
5. **Implementar rate limiting**

### Escalabilidad

#### L√≠mites del sistema:
- **Documentos**: Ilimitado (depende del tier)
- **Consultas concurrentes**: 50-100 (depende del tier)
- **Tama√±o m√°ximo de √≠ndice**: 50GB (Basic)
- **Tokens por minuto**: 50,000 (configurable)

#### Estrategias de escalado:
1. **Vertical**: Aumentar tier de Azure Search
2. **Horizontal**: M√∫ltiples √≠ndices por categor√≠a
3. **Cach√©**: Redis para respuestas frecuentes
4. **CDN**: Para documentos est√°ticos

---

## üîß Troubleshooting

### Errores comunes y soluciones

#### Error: "DeploymentNotFound"
```python
# Problema: Nombre incorrecto del deployment
# Soluci√≥n: Verificar en Azure AI Foundry el nombre exacto
AZURE_OPENAI_CHAT_DEPLOYMENT=nombre-correcto
```

#### Error: "Index not found"
```python
# Problema: El √≠ndice no existe
# Soluci√≥n: Ejecutar cargar_pdf.py para crear el √≠ndice
python cargar_pdf.py
```

#### Error: "Rate limit exceeded"
```python
# Problema: Demasiadas solicitudes
# Soluci√≥n: Implementar retry con backoff
import time

def retry_with_backoff(func, max_retries=3):
    for i in range(max_retries):
        try:
            return func()
        except RateLimitError:
            time.sleep(2 ** i)
    raise Exception("Max retries exceeded")
```

#### Error: "PDF extraction failed"
```python
# Problema: PDF protegido o corrupto
# Soluci√≥n: Usar alternativas como pdfplumber
import pdfplumber

with pdfplumber.open(pdf_path) as pdf:
    text = pdf.pages[0].extract_text()
```

#### Error: "Embedding dimension mismatch"
```python
# Problema: Cambio de modelo de embeddings
# Soluci√≥n: Recrear el √≠ndice con las dimensiones correctas
# ada-002: 1536 dimensiones
# text-embedding-3-small: 1536 dimensiones
# text-embedding-3-large: 3072 dimensiones
```

### Logs y debugging

#### Habilitar logging detallado:
```python
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug.log'),
        logging.StreamHandler()
    ]
)
```

#### Verificar conexiones:
```python
# Test Azure Search
def test_search_connection():
    try:
        search_client.get_document_count()
        print("‚úÖ Azure Search conectado")
    except Exception as e:
        print(f"‚ùå Error: {e}")

# Test Azure OpenAI
def test_openai_connection():
    try:
        response = openai_client.embeddings.create(
            input="test",
            model="embeddings"
        )
        print("‚úÖ Azure OpenAI conectado")
    except Exception as e:
        print(f"‚ùå Error: {e}")
```

---

## üìö Glosario

### T√©rminos t√©cnicos

**Chunk**
: Fragmento de texto de tama√±o fijo extra√≠do de un documento mayor. Unidad b√°sica de indexaci√≥n.

**Embedding**
: Representaci√≥n vectorial num√©rica de texto que captura su significado sem√°ntico. Vector de 1536 dimensiones en nuestro caso.

**B√∫squeda vectorial**
: B√∫squeda basada en similitud coseno entre vectores de embeddings, encuentra contenido sem√°nticamente similar.

**B√∫squeda h√≠brida**
: Combinaci√≥n de b√∫squeda textual tradicional (BM25) con b√∫squeda vectorial para mejores resultados.

**HNSW (Hierarchical Navigable Small World)**
: Algoritmo de b√∫squeda aproximada de vecinos m√°s cercanos usado para b√∫squeda vectorial eficiente.

**Facetas**
: Categor√≠as o filtros que permiten refinar resultados de b√∫squeda (ej: por documento fuente).

**Token**
: Unidad b√°sica de texto procesada por modelos de lenguaje. Aproximadamente 4 caracteres en ingl√©s.

**Temperature**
: Par√°metro que controla la aleatoriedad en la generaci√≥n de texto. 0=determinista, 1=muy creativo.

**Top-k**
: N√∫mero de resultados m√°s relevantes a recuperar en una b√∫squeda.

**TPM (Tokens Per Minute)**
: L√≠mite de procesamiento de tokens por minuto en Azure OpenAI.

**Overlap**
: Superposici√≥n entre chunks consecutivos para mantener contexto.

**Prompt**
: Instrucciones y contexto proporcionados al modelo de lenguaje para generar una respuesta.

**LLM (Large Language Model)**
: Modelo de lenguaje grande como GPT-4o usado para generaci√≥n de texto.

**Hallucination**
: Cuando un LLM genera informaci√≥n falsa o inventada no presente en sus datos de entrenamiento.

**Fine-tuning**
: Proceso de ajustar un modelo preentrenado para una tarea espec√≠fica (no usado en este sistema).

---

## üìà M√©tricas y KPIs

### M√©tricas de rendimiento

```python
# M√©tricas a monitorear
metrics = {
    "response_time": "< 3 segundos",
    "accuracy": "> 90% respuestas correctas",
    "coverage": "> 80% preguntas respondidas",
    "cost_per_query": "< $0.02",
    "uptime": "> 99.9%"
}
```

### Dashboard de monitoreo

```python
def generate_metrics_report():
    return {
        "total_documents": get_document_count(),
        "total_chunks": get_chunk_count(),
        "queries_today": get_daily_queries(),
        "avg_response_time": calculate_avg_response(),
        "top_queries": get_top_queries(),
        "error_rate": calculate_error_rate()
    }
```

---

## üöÄ Pr√≥ximos pasos y mejoras

### Mejoras a corto plazo
1. Implementar cach√© de respuestas
2. Agregar soporte para m√°s formatos (DOCX, TXT)
3. Interfaz web con Streamlit
4. Exportaci√≥n de respuestas a PDF

### Mejoras a mediano plazo
1. OCR para PDFs escaneados
2. Soporte multiidioma
3. Sistema de feedback de usuarios
4. Analytics dashboard

### Mejoras a largo plazo
1. Fine-tuning de modelos
2. Integraci√≥n con Microsoft Teams
3. API REST para integraci√≥n
4. Procesamiento de im√°genes y tablas

---

## üìû Soporte y recursos

### Recursos oficiales
- [Azure AI Search Documentation](https://docs.microsoft.com/azure/search/)
- [Azure OpenAI Documentation](https://docs.microsoft.com/azure/cognitive-services/openai/)
- [Python SDK Documentation](https://docs.microsoft.com/python/api/azure-search-documents/)

### Comunidad
- [Stack Overflow - Azure Search](https://stackoverflow.com/questions/tagged/azure-cognitive-search)
- [GitHub - Azure SDK for Python](https://github.com/Azure/azure-sdk-for-python)
- [Microsoft Q&A](https://docs.microsoft.com/answers/topics/azure-cognitive-search.html)

### Contacto del proyecto
- **Desarrollador**: [Tu nombre]
- **Email**: [Tu email]
- **Repositorio**: [URL del repositorio]
- **√öltima actualizaci√≥n**: Agosto 2024

---

## üìÑ Licencia y cr√©ditos

Este proyecto est√° desarrollado para uso empresarial/educativo.

### Tecnolog√≠as utilizadas:
- Azure AI Search
- Azure OpenAI
- Python 3.x
- PyPDF2
- python-dotenv

### Agradecimientos:
- Equipo de Azure
- Comunidad de Python
- OpenAI

---

*Documento generado el 22 de Agosto de 2024*
*Versi√≥n 1.0*